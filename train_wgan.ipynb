{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(conflict_handler='resolve')\n",
    "parser.add = parser.add_argument\n",
    "parser.add('--gpu_id', type=int, default=1)\n",
    "parser.add('--image_size', type=int, default=16)\n",
    "parser.add('--num_epoch', type=int, default=200)\n",
    "parser.add('--val_epoch_freq', type=int, default=1)\n",
    "parser.add('--batch_size', type=int, default=64)\n",
    "parser.add('--num_channels', type=int, default=256)\n",
    "parser.add('--adv_loss_type', type=str, default='wgan', help='gan|wgan')\n",
    "parser.add('--num_pred', type=int, default=10, help='1|10')\n",
    "parser.add('--stats_weight', type=float, default=1e-4)\n",
    "parser.add('--data_type', type=str, default='norm')\n",
    "parser.add('--target_type', type=str, default='none')\n",
    "parser.add('--train_path', type=str, default='data/ecalNT_50K_e_10_100.npz')\n",
    "parser.add('--val_path', type=str, default='data/ecalNT_10K_e_10_100.npz')\n",
    "parser.add('--regressor_path', type=str, default='checkpoints/classifier/regressor_none')\n",
    "\n",
    "\n",
    "opt, _ = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ezakharov/miniconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '%d' % opt.gpu_id\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from models.dcgan import Generator, Discriminator\n",
    "from src.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from src.stats import Stats\n",
    "from src.utils import Loss\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess data, load stats tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = Stats(opt)\n",
    "train_dataset = Dataset(opt, stats=stats)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "    opt.batch_size, True, num_workers=4, drop_last=True)\n",
    "val_dataset = Dataset(opt, train_dataset, stats)\n",
    "val_loader = DataLoader(val_dataset, \n",
    "    opt.batch_size, True, num_workers=4, drop_last=True)\n",
    "stats.calc_stats(val_dataset.data, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set networks, criterions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(opt.num_channels, opt.image_size).cuda()\n",
    "dis = Discriminator(opt.num_channels, opt.image_size, opt.num_pred).cuda()\n",
    "optim_g = Adam(gen.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "optim_d = Adam(dis.parameters(), lr=1e-4, betas=(0.5, 0.999))\n",
    "crit = Loss(opt, dis, stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "781it [00:18, 42.60it/s]\n",
      "0it [00:00, ?it/s]Process Process-869:\n",
      "Process Process-870:\n",
      "Process Process-872:\n",
      "KeyboardInterrupt\n",
      "Process Process-871:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 115, in default_collate\n",
      "    elif isinstance(batch[0], collections.Mapping):\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/ezakharov/miniconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bc73bca65244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_stats\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# calc loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(opt.num_epoch):\n",
    "    # train for 1 epoch\n",
    "    gen.train()\n",
    "    dis.train()\n",
    "    train_dis_adv_loss = 0\n",
    "    train_gen_adv_loss = 0\n",
    "    train_dis_stats_loss = 0\n",
    "    train_gen_stats_loss = 0\n",
    "    for i, (real_data, real_stats) in tqdm(enumerate(train_loader, 0)):\n",
    "        # update dis\n",
    "        for p in dis.parameters():\n",
    "            p.requires_grad = True\n",
    "        optim_d.zero_grad()\n",
    "        real = Variable(real_data.cuda()) # real data\n",
    "        noise = Variable(torch.randn(opt.batch_size, opt.num_channels)).cuda()\n",
    "        fake = gen(noise) # fake data\n",
    "        # calc loss\n",
    "        real_input = [real]\n",
    "        fake_input = [fake]\n",
    "        if opt.num_pred > 1:\n",
    "            real_input += [Variable(real_stats.cuda())]\n",
    "            fake_input += [stats.calc_stats_torch(fake[:, 0].data)]\n",
    "        loss, loss_adv, loss_stats = crit(real_input, fake_input)\n",
    "        train_dis_adv_loss += loss_adv.data[0]\n",
    "        train_dis_stats_loss += loss_stats.data[0]\n",
    "        loss.backward()\n",
    "        optim_d.step()\n",
    "        # update gen\n",
    "        if opt.adv_loss_type == 'wgan' and (i % 5 != 4):\n",
    "            continue\n",
    "        for p in dis.parameters():\n",
    "            p.requires_grad = False\n",
    "        optim_g.zero_grad()\n",
    "        loss, loss_adv, loss_stats = crit(fake_input)\n",
    "        train_gen_adv_loss += loss_adv.data[0]\n",
    "        train_gen_stats_loss += loss_stats.data[0]\n",
    "        loss.backward()\n",
    "        optim_g.step()\n",
    "    train_dis_adv_loss /= (i+1)\n",
    "    train_gen_adv_loss /= (i+1)\n",
    "    train_dis_stats_loss /= (i+1)\n",
    "    train_gen_stats_loss /= (i+1)\n",
    "    # validate after val_epoch_freq epoch\n",
    "    if e % opt.val_epoch_freq != opt.val_epoch_freq-1:\n",
    "        continue\n",
    "    gen.eval()\n",
    "    dis.eval()\n",
    "    stats.train_dis_adv_loss.append(train_dis_adv_loss)\n",
    "    if opt.adv_loss_type != 'wgan':\n",
    "        stats.train_gen_adv_loss.append(train_gen_adv_loss)\n",
    "    if opt.num_pred > 1:\n",
    "        stats.train_dis_stats_loss.append(train_dis_stats_loss)\n",
    "        stats.train_gen_stats_loss.append(train_gen_stats_loss)\n",
    "    val_dis_adv_loss = 0\n",
    "    val_gen_adv_loss = 0\n",
    "    val_dis_stats_loss = 0\n",
    "    val_gen_stats_loss = 0\n",
    "    val_data_fake = []\n",
    "    for i, (real_data, real_stats) in tqdm(enumerate(val_loader, 0)):\n",
    "        real = Variable(real_data.cuda())\n",
    "        noise = Variable(torch.randn(opt.batch_size, opt.num_channels), volatile=True).cuda()\n",
    "        fake = gen(noise)\n",
    "        # calc loss\n",
    "        real_input = [real]\n",
    "        fake_input = [fake]\n",
    "        if opt.num_pred > 1:\n",
    "            real_input += [Variable(real_stats.cuda())]\n",
    "            fake_input += [stats.calc_stats_torch(fake[:, 0].data)]\n",
    "        loss, loss_adv, loss_stats = crit(real_input, fake_input)\n",
    "        val_dis_adv_loss += loss_adv.data[0]\n",
    "        val_dis_stats_loss += loss_stats.data[0]\n",
    "        loss, loss_adv, loss_stats = crit(fake_input)\n",
    "        val_gen_adv_loss += loss_adv.data[0]\n",
    "        val_gen_stats_loss += loss_stats.data[0]\n",
    "        val_data_fake.append(fake.data.cpu().numpy()[:, 0])\n",
    "    val_dis_adv_loss /= (i+1)\n",
    "    val_gen_adv_loss /= (i+1)\n",
    "    val_dis_stats_loss /= (i+1)\n",
    "    val_gen_stats_loss /= (i+1)\n",
    "    if opt.adv_loss_type == 'wgan':\n",
    "        stats.val_dis_adv_loss.append(val_dis_adv_loss)\n",
    "    if opt.num_pred > 1:\n",
    "        stats.val_dis_stats_loss.append(val_dis_stats_loss)\n",
    "        stats.val_gen_stats_loss.append(val_gen_stats_loss)\n",
    "    val_data_fake = np.concatenate(val_data_fake, 0)\n",
    "    val_data_fake = val_dataset.get_output(val_data_fake, opt.data_type)\n",
    "    clear_output()\n",
    "    stats.calc_stats(val_data_fake)\n",
    "    f = stats.get_plot()\n",
    "    f.savefig('checkpoints/generator/figures/%d.png' % (e+1))\n",
    "    torch.save(gen.state_dict(), 'checkpoints/generator/weights/gen_%d.pkl' % (e+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
