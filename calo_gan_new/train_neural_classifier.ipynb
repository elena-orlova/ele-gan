{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ezakharov/miniconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from src.dataset import get_dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "from src.stats import Stats\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(conflict_handler='resolve')\n",
    "parser.add = parser.add_argument\n",
    "\n",
    "# Dataset opts\n",
    "parser.add('--train_data_path', \n",
    "           default='data/dataset/ecalNT_50K_e_10_100.npz',\n",
    "           help='path to .npz with train data')\n",
    "parser.add('--val_data_path',\n",
    "           default='data/dataset/ecalNT_10K_e_10_100.npz',\n",
    "           help='path to .npz with val data')\n",
    "\n",
    "parser.add('--input_idx', type=str, default='2',\n",
    "           help='inputs to use during training')\n",
    "parser.add('--num_workers', type=int,\n",
    "           help='number of data loading workers', default=6)\n",
    "parser.add('--batch_size', type=int,\n",
    "           default=64, help='batch size')\n",
    "parser.add('--image_size', type=int, default=16,\n",
    "           help='size of the calorimeter image')\n",
    "\n",
    "# Training opts\n",
    "parser.add('--gpu_id', type=int, default=4)\n",
    "parser.add('--num_epoch', type=int, default=100,\n",
    "           help='number of epochs to train for')\n",
    "parser.add('--lr', type=float, default=0.0001,\n",
    "           help='learning rate, default=0.0001')\n",
    "parser.add('--beta1', type=float, default=0.9,\n",
    "           help='beta1 for adam. default=0.9')\n",
    "parser.add('--manual_seed', type=int, default=123, help='manual seed')\n",
    "parser.add('--experiment_name', default='')\n",
    "parser.add('--experiments_dir', default='./data/experiments/',\n",
    "           help='folder to output images and model checkpoints')\n",
    "parser.add('--val_every_epoch', default=1, type=int)\n",
    "\n",
    "# Model opts\n",
    "parser.add('--model_type', type=str, default='dcgan')\n",
    "parser.add('--adv_loss_type', default='wgan', type=str)\n",
    "\n",
    "# Shared opts between generator and discriminator\n",
    "parser.add('--num_channels', default=64, type=int)\n",
    "parser.add('--max_channels', default=256, type=int)\n",
    "\n",
    "# Generator opts\n",
    "parser.add('--in_channels', default=1, type=int)\n",
    "parser.add('--latent_size', default=4, type=int)\n",
    "parser.add('--nonlinearity', default='relu', type=str)\n",
    "parser.add('--norm', default='batch', type=str)\n",
    "\n",
    "# Discriminator opts\n",
    "parser.add('--kernel_size', default=3, type=int)\n",
    "parser.add('--num_preds', default=1, type=int)\n",
    "parser.add('--norm_dis', action='store_true', default=True)\n",
    "\n",
    "opt, _ = parser.parse_known_args()\n",
    "opt.adv_loss_type = opt.adv_loss_type.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = opt.experiments_dir + opt.experiment_name\n",
    "\n",
    "def save_checkpoint(state):\n",
    "    torch.save(state, path + '/checkpoints/%d.pkl' % state['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(adv_loss_type='wgan', batch_size=64, beta1=0.9, experiment_name='', experiments_dir='./data/experiments/', gpu_id=4, image_size=16, in_channels=1, input_idx='2', kernel_size=3, latent_size=4, lr=0.0001, manual_seed=123, max_channels=256, model_type='dcgan', nonlinearity='relu', norm='batch', norm_dis=True, num_channels=64, num_epoch=100, num_preds=1, num_workers=6, train_data_path='data/dataset/ecalNT_50K_e_10_100.npz', val_data_path='data/dataset/ecalNT_10K_e_10_100.npz', val_every_epoch=1)\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(dataset_train,\n",
    " dataloader_train, \n",
    " dataset_val,\n",
    " dataloader_val) = get_dataloader(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models.discriminator import Discriminator\n",
    "from models.generator import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Discriminator(opt).cuda(opt.gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (block): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): LeakyReLU(0.2, inplace)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): LeakyReLU(0.2, inplace)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): LeakyReLU(0.2, inplace)\n",
      "    (9): View()\n",
      "    (10): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "374209\n"
     ]
    }
   ],
   "source": [
    "num_params = 0\n",
    "for p in model.parameters():\n",
    "    num_params += p.numel()\n",
    "print(model)\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5, verbose=True, threshold=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crit = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9777731568804167 1.6434820271455324\n",
      "2.2752407502273284 2.2309301052338038\n",
      "1.9739049663159056 1.3030141848020065\n",
      "1.5614736125960698 2.2596454322338104\n",
      "1.3972986431723216 0.8328422414950836\n",
      "1.2532895816807252 0.9012462462370212\n",
      "1.2921074746360242 0.882700040172308\n",
      "1.2719739684680054 0.6521281355466598\n",
      "1.1592978010104347 1.1014881134033203\n",
      "1.1760287380249033 1.1880318285563054\n",
      "1.140844982007707 1.3194569593820817\n",
      "1.20971872772969 1.2033885778524938\n",
      "1.1658148746865964 1.822156657775243\n",
      "1.0755846590452403 0.8829072018464407\n",
      "Epoch    13: reducing learning rate of group 0 to 5.0000e-03.\n",
      "0.8725434770275781 0.6659354951519233\n",
      "0.8549669645583584 0.6881231984648949\n",
      "0.8645370636950992 1.306852278036949\n",
      "0.8153068739992403 0.8947243786010987\n",
      "0.8254305529533367 0.5185649631879269\n",
      "0.8382722790354192 0.5610758709983948\n",
      "0.8261646601286802 0.7723526878234668\n",
      "0.8192445919699919 0.7660139015851877\n",
      "0.7612770613039654 0.9350725729496051\n",
      "0.7671809791755432 0.8675294392384015\n",
      "0.8029862975799472 0.8045773594043194\n",
      "Epoch    24: reducing learning rate of group 0 to 2.5000e-03.\n",
      "0.6892023409374545 0.5501466989517212\n",
      "0.6585086656975228 1.0293501917368326\n",
      "0.6400097695569222 0.5764259413266793\n",
      "0.6355643055274147 0.9218861621159774\n",
      "0.6571362820691244 0.84507889014024\n",
      "0.6609700175238328 0.5550377009770809\n",
      "Epoch    30: reducing learning rate of group 0 to 1.2500e-03.\n",
      "0.6027625546946873 0.9645728679039539\n",
      "0.5728224993286304 1.2194372572195835\n",
      "0.5888282051846556 0.6329370454335824\n",
      "0.5961759408289583 0.5573498379343595\n",
      "0.578309932835734 0.9341068260180645\n",
      "0.5893823754008998 0.708120923775893\n",
      "Epoch    36: reducing learning rate of group 0 to 6.2500e-04.\n",
      "0.5542407294928493 0.633783628543218\n",
      "0.5695868711847044 0.711241602515563\n",
      "0.5620275387843349 0.9770315025861447\n",
      "0.5542036044612889 0.7229411938251593\n",
      "0.5597833706383211 1.2630736174491735\n",
      "0.5479082960478017 0.8601105037407998\n",
      "Epoch    42: reducing learning rate of group 0 to 3.1250e-04.\n",
      "0.5301982785614443 0.8881597117735789\n",
      "0.5284248076465158 0.8057909313684855\n",
      "0.5332993494105858 0.6042708492813966\n",
      "0.5313009101892708 0.9524632638845688\n",
      "0.5292792002385466 0.6444294552008311\n",
      "0.536252433374505 1.039949704057131\n",
      "Epoch    48: reducing learning rate of group 0 to 1.5625e-04.\n",
      "0.5226083399010071 1.3555004317791035\n",
      "0.5246034971654187 0.6676859336021619\n",
      "0.5247519218127951 0.6644934496054282\n",
      "0.5179715495408727 1.3048645154787943\n",
      "0.5236852214446294 0.800372797709245\n",
      "0.525348108152116 0.7444672053441023\n",
      "Epoch    54: reducing learning rate of group 0 to 7.8125e-05.\n",
      "0.5127261131811081 0.5223486308868115\n",
      "0.5191542816070527 0.7452244002085465\n",
      "0.5180637088917892 0.9808161281622373\n",
      "0.5234437300209505 0.9028195188595698\n",
      "0.5201599850544704 0.5418007606879259\n",
      "0.5186458298323554 0.5141042235952157\n",
      "Epoch    60: reducing learning rate of group 0 to 3.9063e-05.\n",
      "0.5123453140258789 0.9846636011050298\n",
      "0.5159794643578548 0.6297928249606719\n",
      "0.512821531173667 0.6175301214441274\n",
      "0.5204219530776582 1.6051060121793013\n",
      "0.5219609912165301 0.7979475974272459\n",
      "0.5151772914637982 1.8804992116414583\n",
      "Epoch    66: reducing learning rate of group 0 to 1.9531e-05.\n",
      "0.5202253627258134 2.0600188894149585\n",
      "0.5088364710881066 0.6995253131175653\n",
      "0.5123300933196816 1.2044259642179196\n",
      "0.5092287809610672 1.040048470099767\n",
      "0.5198289172368532 0.9437095989019443\n",
      "0.5228984690200962 0.8303817285177035\n",
      "Epoch    72: reducing learning rate of group 0 to 9.7656e-06.\n",
      "0.5159708063443705 0.6650787922434318\n",
      "0.5100891357347388 0.9362550985354644\n",
      "0.5131147262686804 1.020773668701832\n",
      "0.5115296040088053 0.7811962354641694\n",
      "0.511866727688859 0.7638547584796563\n",
      "0.5150734244174444 0.5961173140467741\n",
      "Epoch    78: reducing learning rate of group 0 to 4.8828e-06.\n",
      "0.5102428460014309 0.6597046131889025\n",
      "0.5158667642618416 0.6283825779190431\n",
      "0.508641337539414 0.9056899700409327\n",
      "0.5033497882866218 0.6153690253312771\n",
      "0.5102713499575968 0.7627599667280148\n",
      "0.5123634906187559 1.2713056787466392\n",
      "Epoch    84: reducing learning rate of group 0 to 2.4414e-06.\n",
      "0.5171396985325709 0.7893342815148525\n",
      "0.5152886577437079 0.760297872317143\n",
      "0.5163658635259133 0.6778623538139539\n",
      "0.517916326638831 0.9066811979581149\n",
      "0.5149765886585783 0.8663530418506036\n",
      "0.5165130655148881 0.6310662212662208\n",
      "Epoch    90: reducing learning rate of group 0 to 1.2207e-06.\n",
      "0.5131136226669316 0.782984095506179\n",
      "0.5121848530943354 0.6314481777640489\n",
      "0.5200237714603219 0.6473434464289591\n",
      "0.5116196119067916 0.8699544973862476\n",
      "0.5115785079789986 0.8064173830625339\n",
      "0.5101885317458691 0.5739813095484024\n",
      "Epoch    96: reducing learning rate of group 0 to 6.1035e-07.\n",
      "0.5100983958238218 0.6195196134921832\n",
      "0.5179635039059667 0.6508401276973578\n",
      "0.5111181692490963 0.6660561806116349\n"
     ]
    }
   ],
   "source": [
    "loss_min = 1e8\n",
    "\n",
    "for epoch in range(1, opt.num_epoch + 1):\n",
    "\n",
    "    model.train()\n",
    "    loss_mse_train = 0\n",
    "\n",
    "    for i, (input, target) in enumerate(dataloader_train, 1):\n",
    "        \n",
    "        input = Variable(input.cuda(opt.gpu_id))\n",
    "        target = Variable(target.cuda(opt.gpu_id))\n",
    "        \n",
    "        pred = model(target)\n",
    "        loss = crit(pred, input)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_mse_train += loss.data[0]\n",
    "    \n",
    "    loss_mse_train /= i\n",
    "\n",
    "    if epoch % opt.val_every_epoch:\n",
    "        continue\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_mse_val = 0\n",
    "\n",
    "    for i, (input, target) in enumerate(dataloader_val, 1):\n",
    "\n",
    "        input = Variable(input.cuda(opt.gpu_id))\n",
    "        target = Variable(target.cuda(opt.gpu_id))\n",
    "        \n",
    "        pred = model(target)\n",
    "        \n",
    "        loss = crit(pred, input)\n",
    "\n",
    "        loss_mse_val += loss.data[0]\n",
    "\n",
    "    loss_mse_val /= i    \n",
    "    print(loss_mse_train, loss_mse_val)\n",
    "    \n",
    "    scheduler.step(loss_mse_val)\n",
    "    \n",
    "    if loss_mse_val < loss_min:\n",
    "        torch.save(model, 'data/utils/classifier.pth')\n",
    "        loss_min = loss_mse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5141042235952157\n"
     ]
    }
   ],
   "source": [
    "print(loss_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (block): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): LeakyReLU(0.2, inplace)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (5): LeakyReLU(0.2, inplace)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (8): LeakyReLU(0.2, inplace)\n",
       "    (9): View()\n",
       "    (10): Linear(in_features=4096, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('data/utils/classifier.pth')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
